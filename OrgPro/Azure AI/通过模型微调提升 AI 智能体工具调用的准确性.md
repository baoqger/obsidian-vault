
11月底微软举行了2025 Ignite大会(这个大会明显不如AWS的re:Invent话题度高), Chris一直以来都在持续关注微软AI平台(微软虽然不受普通人待见, 但是它的平台自然有其受众群体, 有客户, 就有生意, 也就有我们的一些些机会). Ignite大会上 ,发布了最新的Microsoft Foundry平台, 并且展示了很多技术案例的演示, 后续Chris会给大家逐步拆解. 

今天先从Fine Tune Model这个比较复杂的话题入手: 通过模型微调提升 AI 智能体工具调用的准确性(可以按照这个英文标题去搜 Enhancing AI Agent tool-calling accuracy through Fine-Tuning) 

### 背景问题

Agent调用工具(Tool)来获取外界数据或者完成一些任务, 这是Agent最常见的一个工作模式了. 

这种模式, 对于只需要一次(或者少数几次)工具调用就能解决的简单问题, 一般都能稳定处理! 

但是如果当用户的提问变得很复杂时, Agent还能计划出很好的工具调用吗? 制定出的计划, 还能稳定执行吗? 如果不能, 在什么场合适合Fine Model这个方案呢? 

### 项目背景

这个案例虚构一个名为 **Zava** 的零售品牌。该品牌提供由一个 **Retail MCP 服务器** 驱动的客服 AI 智能体，该MCP服务器对外暴露了各种工具（商品搜索、用户查询、订单详情、退货、换货、资料更新等）。

![[Pasted image 20251215205407.png]]

### 简单用例可以正常工作

我们先展示基础模型（例如 `gpt-4.1-mini`）可以正确处理**简单的工具调用**。  
比如，像下面这样的请求：

> “Can you show me all your products?”（“你能把你们所有的商品都给我看看吗？”）

会被解析为正确的 MCP 工具调用，并产生预期结果。

智能体通常会按如下方式响应：

1. 将该请求理解为浏览商品的意图
2. 调用合适的 MCP 工具（例如 `list_products`），且**不带任何参数**
3. 向用户返回一个友好的、分页展示的商品列表

![[Pasted image 20251215210209.png]]

### 更真实的场景失败：更新我的地址

现在来看一个更加真实、且与策略高度相关的场景。

一位回访客户在搬家后希望**更新自己的地址**：

> “Hi, I want to update my address.”  
> （“嗨，我想更新一下我的地址。”）

根据写进Agent系统指令里的策略，我们知道智能体应该：

1. **对用户进行身份验证**
    - 询问邮箱，或
    - 询问名字、姓氏以及邮政编码（ZIP code）
2. 调用 `find_user_id_by_name_zip` 或 `find_user_id_by_email`, 返回user_id
3. 立即使用返回的 `user_id` 调用 `get_user_details`
4. 展示当前地址，并请用户确认新地址
5. 使用正确的 `user_id` 和新地址调用 `update_address`
6. 确认更新已完成

下面记录了一段真实对话：在这段对话中，发现智能体的行为**并不正确**。

![[Pasted image 20251215211314.png]]

通过查看打印出的对话记录，我们可以发现如下模式：

1. 用户请求更新自己的地址。
    
2. 助手正确地询问了身份信息（姓名 + 邮政编码）。
    
3. 用户回答，例如：“My name is Noah Brown and ZIP is 80279”（“我叫 Noah Brown，邮编是 80279”）。
    
4. 智能体调用工具：find_user_id_by_name_zip, 该工具返回了一个有效的 user_id :noah_brown_6181, 这是正确的行为! 

5. 之后，当用户说 “can you show me my current details first”时，智能体调用工具：get_user_details, 参数是 { "user_id": "noah_brown_80279" } 这是错误的——模型并没有使用刚刚返回的 user_id（noah_brown_6181），而是幻觉出一个user_id 的值( noah_brown_80279）

### 这个失败场景为何重要?

这个失败场景之所以重要，是因为它凸显了构建可靠的工具调用型智能体时遇到的真实挑战：

- 这不是自然语言理解问题, 模型是理解这个请求的。  

- 这不是工具选择问题: 模型选择了正确的工具

- 这是工具参数传递（propagation）的问题, 这是一个**结构性错误**

- 这是策略合规性失败, 因为Agent的系统提示词中, 明确要求了: 
	- 对用户进行身份验证
	- 立刻检索用户档案
	- 正确传递返回的 `user_id`
	- 绝不能凭空编造标识符
	- 绝不能在对话中途凭空“换一个”用户

 - 这是数据模型一致性失败, 因为被幻觉出来的用户 ID 在 MPC服务的数据后台中根本不存在, 这意味着：
	- 模型并没有基于真实后端数据, 生成对话
	- 模型也没有把工具输出结果当作权威来源
	- 模型破坏了多轮对话中的状态连续性


### 为什么需要微调?

这样的失败具有以下特点：

- 这是所有基础模型都要面对的通用问题（即使是很强的模型）
- 对真实世界中的智能体来说至关重要（涉及身份、支付、退货等）
- 正是可以通过 SFT（监督微调）+ 评估来修复的行为类型

这类失败, 比如参数传递错误、漏掉中间调用、或跳过某些策略中的步骤——在多轮工具调用智能体中非常常见，而这正是微调和结构化评估所要改进的核心问题。

### 微调的流程

![[Pasted image 20251220085218.png]]

- 微调目标: 提供Agent在多轮工具调用中的准确性
- 微调方法: 从最常见的SFT（监督微调）开始尝试
- 训练数据: 因为我们的目标是提升Agent工具调用的准确性, 所以我们SFT的训练数据, 就应该是用户提问和能够满足用户需求的工具调用链. 
- 模型评估: 只有能够量化评估模型, 才能评价微调的效果. 所以我们需要对原始模型: gpt-4.1-mini 先进行评估; 然后再得到微调模型后, 再进行一轮评估

### 合成数据与知识蒸馏 (Synthetic Data & Knowledge Distillation)

模型微调中的重要一环就是准备微调训练数据. 
相比手动准备数据的费时费力, 合成数据(Synthetic Data)可以通过算法来快速完成任务. 
在这个案例里, 我们使用最常见的一种合成数据方法: 知识蒸馏(Knowledge Distillation)

知识蒸馏是一种用“大模型教小模型”的训练方法。把性能更强的大模型当作老师，让它对各种问题做出回答，再用这些答案信息来训练参数更少、推理更便宜的小模型。

在我们这个案例中, 我们先编造尽量真实的用户查询,  让更高级的模型, 比如 GPT-4.1 / GPT-4o 来做以下事情：
- 决定要调用哪些工具以及调用顺序
- 生成包含工具调用和参数的、完整展开的对话

Microsoft Foundry 在微调工作流中可以轻松支持合成数据生成

![[Pasted image 20251220093040.png]]

合成数据如下, 包括训练和验证两个数据集. 

![[Pasted image 20251220095410.png]]
### 模型评估

在微调之前, 我们先对当前使用的基座模型: gpt-4.1-mini做一个评估, 评估数据就是基于上面数据合成步骤拿到的验证数据集(validation dataset). 

![[Pasted image 20251220095757.png]]

除了gpt-4.1-mini之外, 我们还可以看看其他两个基座模型: gpt-4.1-nano和gpt-4.1的效果. 可以看到, 更新更强大的基座模型, 表现就要显著的好一些. 而我们用在Agent里的gpt-4.1-mini, 评分为57%. 稍后Fine tune之后, 我们关注下, 这个评分是否被提高了. 

### 微调模型

在Foundry平台, 我们可以通过本地运行代码通过SDK提交fine tuning job, 另一种方式是直接从UI上构建类似的job. 具体操作都非常简单, 此处省略. 

![[Pasted image 20251220120926.png]]

![[Pasted image 20251220120843.png]]
可以看出, 我们的训练的关键指标非常理想, loss = 0.03, accuracy = 0.99

### 微调模型效果验证

首先, 可以把新微调模型 - gpt-4.1-mini-sft-2 , 嵌入我们的Agent, 然后把刚刚失败的那个复杂工具调用场景再来一遍:  

![[Pasted image 20251219214551.png]]

可以看到, 新模型的行为优化了很多: 
- 工具参数传递(propagation)的过程, 不再产生幻觉
- 多轮工具调用的路径更加准确. 比如这里, 调用 `find_user_id_by_name_zip` , 返回user_id, 立即使用返回的 `user_id` 调用 `get_user_details`, 不需要用户再次介入! 这些都是我们的微调训练数据集里重点突出的, 也确实实现了效果! 

另外, evaluation评估的结果, 也涨到了87%. 非常有效! 
![[Pasted image 20251220204927.png]]
### 最终结果

你得到了一个更小的模型，但是在你特定的零售场景中，能够表现得像那个大型教师模型——但成本和延迟都更低，而且在推理时所需的提示词也要简单得多。


#### Cost分析

![[Pasted image 20251222152342.png]]


